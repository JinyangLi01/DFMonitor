{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# collaborative_filtering with exponential time decay (GPT)",
   "id": "40087b909979ef88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T23:23:49.908714Z",
     "start_time": "2024-09-16T23:23:34.655028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from river import datasets, metrics\n",
    "\n",
    "# Initialize data structures\n",
    "user_ratings = defaultdict(dict)\n",
    "user_timestamps = defaultdict(dict)\n",
    "similarity = defaultdict(dict)\n",
    "\n",
    "# Initialize classification metrics\n",
    "accuracy = metrics.Accuracy()\n",
    "precision = metrics.Precision()\n",
    "recall = metrics.Recall()\n",
    "f1 = metrics.F1()\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.MovieLens100K()\n",
    "\n",
    "headers = [\"user\", \"item\", \"timestamp\", \"title\", \"release_date\", \"genres\",\n",
    "           \"age\", \"age_2groups\", \"age_4groups\", \"gender\", \"occupation\", \"zip_code\",\n",
    "           \"rating\", \"prediction\", \"datetime\", \"rating_binary\", \"prediction_binary\",\n",
    "           \"diff\", \"diff_binary_correctness\"]\n",
    "\n",
    "def time_decay_weight(interaction_time, current_time, decay_rate=0.000001):\n",
    "    \"\"\"\n",
    "    Calculate the time decay weight for an interaction.\n",
    "\n",
    "    Parameters:\n",
    "    - interaction_time: The timestamp of the interaction.\n",
    "    - current_time: The current timestamp.\n",
    "    - decay_rate: The rate at which the influence of older data decays.\n",
    "\n",
    "    Returns:\n",
    "    - A float representing the time decay weight.\n",
    "    \"\"\"\n",
    "    time_difference = current_time - interaction_time\n",
    "    return np.exp(-decay_rate * time_difference)\n",
    "\n",
    "def compute_similarity(user1, user2, current_time, decay_rate):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two users using time-decayed ratings.\n",
    "\n",
    "    Parameters:\n",
    "    - user1, user2: The user IDs.\n",
    "    - current_time: The current timestamp.\n",
    "    - decay_rate: The time decay rate.\n",
    "\n",
    "    Returns:\n",
    "    - A float representing the similarity between user1 and user2.\n",
    "    \"\"\"\n",
    "    common_items = set(user_ratings[user1]) & set(user_ratings[user2])\n",
    "    if not common_items:\n",
    "        return 0\n",
    "    ratings1 = []\n",
    "    ratings2 = []\n",
    "    for item in common_items:\n",
    "        # Calculate time decay weights for both users\n",
    "        time1 = user_timestamps[user1][item]\n",
    "        time2 = user_timestamps[user2][item]\n",
    "        weight1 = time_decay_weight(time1, current_time, decay_rate)\n",
    "        weight2 = time_decay_weight(time2, current_time, decay_rate)\n",
    "        ratings1.append(user_ratings[user1][item] * weight1)\n",
    "        ratings2.append(user_ratings[user2][item] * weight2)\n",
    "    # Use Pearson correlation coefficient\n",
    "    mean1 = sum(ratings1) / len(ratings1)\n",
    "    mean2 = sum(ratings2) / len(ratings2)\n",
    "    numerator = sum((r1 - mean1) * (r2 - mean2) for r1, r2 in zip(ratings1, ratings2))\n",
    "    denominator = (sum((r - mean1) ** 2 for r in ratings1) * sum((r - mean2) ** 2 for r in ratings2)) ** 0.5\n",
    "    return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "# Open the CSV file for writing and write the header\n",
    "with open(\"movielens_online_cf_time_decay.csv\", \"w\", newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    decay_rate = 0.000001  # Adjust this value as needed\n",
    "\n",
    "    for x, y in dataset:\n",
    "        user_id = x['user']\n",
    "        item_id = x['item']\n",
    "\n",
    "        # Get the current time (simulating real-time streaming)\n",
    "        current_time = time.time()\n",
    "\n",
    "        # Initialize prediction\n",
    "        pred = None\n",
    "\n",
    "        # Only proceed if user_id is already in user_ratings\n",
    "        if user_id in user_ratings:\n",
    "            similarities = {}\n",
    "            for other_user in user_ratings:\n",
    "                if other_user != user_id:\n",
    "                    # Check if similarity has been computed before\n",
    "                    if user_id in similarity and other_user in similarity[user_id]:\n",
    "                        sim = similarity[user_id][other_user]\n",
    "                    else:\n",
    "                        sim = compute_similarity(user_id, other_user, current_time, decay_rate)\n",
    "                        # Store the computed similarity\n",
    "                        similarity[user_id][other_user] = sim\n",
    "                        similarity[other_user][user_id] = sim\n",
    "                    # Only consider users with positive similarity who have rated the item\n",
    "                    if sim > 0 and item_id in user_ratings[other_user]:\n",
    "                        similarities[other_user] = sim\n",
    "\n",
    "            if similarities:\n",
    "                numerator = 0.0\n",
    "                denominator = 0.0\n",
    "                for other_user in similarities:\n",
    "                    # Apply time decay to the neighbor's rating\n",
    "                    time_of_rating = user_timestamps[other_user][item_id]\n",
    "                    weight = time_decay_weight(time_of_rating, current_time, decay_rate)\n",
    "                    numerator += similarities[other_user] * user_ratings[other_user][item_id] * weight\n",
    "                    denominator += abs(similarities[other_user]) * weight\n",
    "                pred = numerator / denominator if denominator != 0 else None\n",
    "\n",
    "        # Default prediction if None\n",
    "        if pred is None:\n",
    "            pred = 3.0  # Average rating in MovieLens dataset\n",
    "\n",
    "        # Add the actual rating and the prediction to the dictionary\n",
    "        x['rating'] = y\n",
    "        x['prediction'] = pred\n",
    "        preds = pred\n",
    "\n",
    "        x[\"rating_binary\"] = int(y >= 4)\n",
    "        x[\"prediction_binary\"] = int(preds >= 4) if preds is not None else None\n",
    "        x[\"diff\"] = abs(y - preds)\n",
    "        x[\"diff_binary_correctness\"] = int(abs(y - preds) <= 1)\n",
    "        x[\"datetime\"] = pd.to_datetime(x['timestamp'], unit='ns').strftime('%Y-%m-%d')\n",
    "\n",
    "        # Age groupings\n",
    "        if x[\"age\"] <= 30:\n",
    "            x[\"age_2groups\"] = \"7-30\"\n",
    "        else:\n",
    "            x[\"age_2groups\"] = \"31-73\"\n",
    "\n",
    "        if x[\"age\"] <= 24:\n",
    "            x[\"age_4groups\"] = \"7-24\"\n",
    "        elif x[\"age\"] <= 30:\n",
    "            x[\"age_4groups\"] = \"25-30\"\n",
    "        elif x[\"age\"] <= 40:\n",
    "            x[\"age_4groups\"] = \"31-40\"\n",
    "        else:\n",
    "            x[\"age_4groups\"] = \"41-73\"\n",
    "\n",
    "        writer.writerow(x)\n",
    "\n",
    "        # Update the user ratings and timestamps AFTER making the prediction\n",
    "        user_ratings[user_id][item_id] = y\n",
    "        user_timestamps[user_id][item_id] = x['timestamp']\n",
    "\n",
    "        # Update classification metrics\n",
    "        if preds is not None:\n",
    "            y_binary = int(y >= 4)\n",
    "            pred_binary = int(preds >= 4)\n",
    "            accuracy.update(y_binary, pred_binary)\n",
    "            precision.update(y_binary, pred_binary)\n",
    "            recall.update(y_binary, pred_binary)\n",
    "            f1.update(y_binary, pred_binary)\n",
    "\n",
    "# Output the final results\n",
    "print(f\"Accuracy: {accuracy.get():.4f}\")\n",
    "print(f\"Precision: {precision.get():.4f}\")\n",
    "print(f\"Recall: {recall.get():.4f}\")\n",
    "print(f\"F1 Score: {f1.get():.4f}\")\n"
   ],
   "id": "6b01a093dc15818f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/m1107g5j24x3w6mcyb9njvyw0000gn/T/ipykernel_89535/790445842.py:40: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-decay_rate * time_difference)\n",
      "/var/folders/sy/m1107g5j24x3w6mcyb9njvyw0000gn/T/ipykernel_89535/790445842.py:70: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  numerator = sum((r1 - mean1) * (r2 - mean2) for r1, r2 in zip(ratings1, ratings2))\n",
      "/var/folders/sy/m1107g5j24x3w6mcyb9njvyw0000gn/T/ipykernel_89535/790445842.py:71: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  denominator = (sum((r - mean1) ** 2 for r in ratings1) * sum((r - mean2) ** 2 for r in ratings2)) ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4462\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T22:47:33.528032Z",
     "start_time": "2024-09-16T22:47:33.516083Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "45e36165e234f5b3",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7b1f51f15b34d5df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# collaborative_filtering with exponential time decay (github)  FAIL\n",
    "https://github.com/gucino/Temporal-Collaborative-Filtering-using-decay-function-to-track-dynamic-interest-of-user/blob/master/Temporal_CF_decay_funnction.py"
   ],
   "id": "5a9b78c11ec4721b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T23:15:57.825248Z",
     "start_time": "2024-09-16T23:15:57.705789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May 10 21:20:54 2020\n",
    "\n",
    "@author: Tisana\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from river import datasets\n",
    "\n",
    "# Load the dataset\n",
    "data_set = datasets.MovieLens100K()\n",
    "\n",
    "\n",
    "##clean data\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "#compute user rating matrix and timestamp matrix\n",
    "num_user=943 #user id 1 to 943\n",
    "num_movie=1682 #movie id 1 to 1682\n",
    "\n",
    "user_rating_dict={}\n",
    "#key is user id : value are rating of all movie \n",
    "for user_id in range(1,num_user+1):\n",
    "    user_rating_dict[user_id]=np.array([0]*num_movie)\n",
    "    \n",
    "user_timestamp_dict={}\n",
    "for user_id in range(1,num_user+1):\n",
    "    user_timestamp_dict[user_id]=np.array([0]*num_movie)\n",
    "\n",
    "#append rating data set to user rating dict\n",
    "data_set_list=data_set.tolist()\n",
    "for each_row in data_set_list:\n",
    "    user_id=each_row[0]\n",
    "    mmovie_id=each_row[1]\n",
    "    rating=each_row[2]\n",
    "    movie_index=mmovie_id-1\n",
    "    timestamp=each_row[3]\n",
    "    #append to dictionary\n",
    "    user_rating_dict[user_id][movie_index]=rating\n",
    "    user_timestamp_dict[user_id][movie_index]=timestamp\n",
    "\n",
    "user_rating_array=[]\n",
    "for each in user_rating_dict.values():\n",
    "    user_rating_array.append(each)\n",
    "user_rating_array=np.array(user_rating_array) #index by user index (user id -1)\n",
    "\n",
    "#convert rating matrix to user-like matrix\n",
    "user_like_matrix=[]\n",
    "for i in range(0,num_user):\n",
    "    row_list=[]\n",
    "    for j in range(0,num_movie):\n",
    "        rating=user_rating_array[i,j]\n",
    "        if rating>=3:\n",
    "            row_list.append(1)\n",
    "        else:\n",
    "            row_list.append(0)\n",
    "    user_like_matrix.append(np.array(row_list))\n",
    "user_like_matrix=np.array(user_like_matrix)\n",
    "\n",
    "#convert user-like matrix to user-user network\n",
    "user_user_network=[]\n",
    "for i in range(0,num_user):\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "    row_list=[]\n",
    "    for j in range(0,num_user):\n",
    "        common_prefered_item=user_like_matrix[i,:]*user_like_matrix[j,:]\n",
    "        row_list.append(common_prefered_item)\n",
    "    row_list=np.array(row_list).sum(axis=1)\n",
    "    user_user_network.append(row_list)\n",
    "user_user_network=np.array(user_user_network)\n",
    "#normalization\n",
    "row_mean=np.mean(user_rating_array,axis=1)\n",
    "row_mean=row_mean[:,np.newaxis]\n",
    "user_rating_array=(user_rating_array-row_mean)*(user_rating_array)/(user_rating_array)\n",
    "\n",
    "for each_row in range(0,num_user):\n",
    "    for each_column in range(0,num_movie):\n",
    "        if np.isnan(user_rating_array[each_row,each_column])==True:\n",
    "            user_rating_array[each_row,each_column]=0\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "#get timestamp matrix\n",
    "user_timestamp_array=[]\n",
    "for each in user_timestamp_dict.values():\n",
    "    user_timestamp_array.append(each)\n",
    "user_timestamp_array=np.array(user_timestamp_array) \n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "#compute user similarity matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "user_similarity_matrix=[]\n",
    "for i in range(0,num_user):\n",
    "    if i%10==0:\n",
    "        print(i,\" out of \",num_user)\n",
    "    user_1_id=i+1\n",
    "    row=[]\n",
    "    for j in range(0,num_user):\n",
    "        user_2_id=j+1\n",
    "        similarity=pearsonr(user_rating_array[user_1_id-1],user_rating_array[user_2_id-1])[0]\n",
    "        #similarity=cosine_similarity([user_rating_array[user_1_id-1]],[user_rating_array[user_2_id-1]])[0][0]\n",
    "        row.append(similarity)\n",
    "    user_similarity_matrix.append(np.array(row))    \n",
    "user_similarity_matrix=np.array(user_similarity_matrix)    \n",
    "\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################   \n",
    "#prediction function\n",
    "\n",
    "def faster_rating_prediction(k,user_similarity_matrix,time,alpha,user_timestamp_array):\n",
    "    #avg rating of all user matrix\n",
    "    avg_rating_user_matrix=np.mean(user_rating_array,axis=1)\n",
    "    avg_rating_user_matrix=avg_rating_user_matrix[:,np.newaxis]\n",
    "    avg_rating_user_matrix=np.repeat(avg_rating_user_matrix,num_movie,axis=1)\n",
    "    \n",
    "    predicted_rating_array=[]\n",
    "    for target_user_index in range(0,num_user):\n",
    "        \n",
    "        #avg rating of target user\n",
    "        avg_rating_of_target_user=avg_rating_user_matrix[target_user_index,:]\n",
    "        \n",
    "        #find k similar user\n",
    "        lst=pd.Series(list(user_similarity_matrix[target_user_index,:]))\n",
    "        i=lst.nlargest(k+1)\n",
    "        similar_user_index_list=i.index.values.tolist()\n",
    "        similar_user_index_list=similar_user_index_list[1:] #exclude yourself\n",
    "        \n",
    "        #avg rating of similar user\n",
    "        avg_rating_of_similar_user=avg_rating_user_matrix[similar_user_index_list,:]\n",
    "        rating_of_similar_user=user_rating_array[similar_user_index_list,:]\n",
    "        diff_of_similar_user=rating_of_similar_user-avg_rating_of_similar_user\n",
    "        \n",
    "        \n",
    "        \n",
    "        time_diff=weighted_time(target_user_index,similar_user_index_list,alpha,user_timestamp_array)\n",
    "        \n",
    "        #check for time\n",
    "        if time==True:\n",
    "            diff_of_similar_user=diff_of_similar_user*time_diff\n",
    "        \n",
    "        #second term\n",
    "        similarity_to_target_user=user_similarity_matrix[target_user_index,similar_user_index_list]\n",
    "        similarity_to_target_user=similarity_to_target_user[:,np.newaxis]\n",
    "        numerator=sum(diff_of_similar_user*similarity_to_target_user)\n",
    "        \n",
    "        if time==True:\n",
    "            denominator=sum(similarity_to_target_user*time_diff)\n",
    "        else:\n",
    "            denominator=sum(similarity_to_target_user)\n",
    "        \n",
    "        \n",
    "        second_term=numerator/denominator\n",
    "        \n",
    "        #prediction\n",
    "        predicted_rating_of_target_user=avg_rating_of_target_user+second_term\n",
    "        predicted_rating_array.append(predicted_rating_of_target_user)\n",
    "\n",
    "    predicted_rating_array=np.array(predicted_rating_array)\n",
    "    return predicted_rating_array\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "######################################################################## \n",
    "#MAE function\n",
    "def MAE_calculator(predicted_user_rating_array,user_rating_array):\n",
    "    #change predict matrix to have only known value\n",
    "    filter_matrix=np.copy(user_rating_array)\n",
    "    filter_matrix[filter_matrix>0]=1\n",
    "    predicted_user_rating_array=predicted_user_rating_array*filter_matrix\n",
    "    \n",
    "    num_predict=np.count_nonzero(predicted_user_rating_array)\n",
    "    MAE=(abs(predicted_user_rating_array-user_rating_array).sum())/num_predict\n",
    "    return MAE\n",
    "\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################     \n",
    "\n",
    "#generate abs time diff matrix\n",
    "def weighted_time(target_user_index,similar_user_index_list,alpha,user_timestamp_array):\n",
    "\n",
    "\n",
    "    a=user_timestamp_array[target_user_index,:]\n",
    "    b=user_timestamp_array[similar_user_index_list,:]\n",
    "    time_diff_matrix=abs(a-b)\n",
    "    \n",
    "    #standardization\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler=StandardScaler()\n",
    "    time_diff_matrix = scaler.fit_transform(time_diff_matrix)\n",
    "    lam_matrix=np.exp(-1*time_diff_matrix*alpha)\n",
    "    return lam_matrix\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "######################################################################## \n",
    "#find best value of alpha (1.7)\n",
    "k=3\n",
    "MAE_list=[]\n",
    "alpha_list=[]\n",
    "alpha=0\n",
    "for i in range(0,100):\n",
    "    predicted_rating=faster_rating_prediction(k,user_similarity_matrix,True,alpha,user_timestamp_array)\n",
    "    MAE=MAE_calculator(predicted_rating,user_rating_array)\n",
    "    MAE_list.append(MAE)\n",
    "    alpha_list.append(alpha)\n",
    "    print(\" MAE : \",MAE)\n",
    "    alpha+=0.1\n",
    "plt.title(\"find best value of alpha\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.plot(alpha_list,MAE_list)\n",
    "best_alpha_index=MAE_list.index(min(MAE_list))\n",
    "best_alpha=alpha_list[best_alpha_index]\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "######################################################################## \n",
    "#compare performance of no time and time\n",
    "alpha=best_alpha\n",
    "MAE_time_list=[]\n",
    "MAE_no_time_list=[]\n",
    "k_list=[]\n",
    "for k in range(1,100,10):\n",
    "    print(\"k : \",k)\n",
    "    time=faster_rating_prediction(k,user_similarity_matrix,True,alpha,user_timestamp_array)\n",
    "    no_time=faster_rating_prediction(k,user_similarity_matrix,False,alpha,user_timestamp_array)\n",
    "    \n",
    "    MAE_time=MAE_calculator(time,user_rating_array)\n",
    "    MAE_no_time=MAE_calculator(no_time,user_rating_array)\n",
    "    \n",
    "    MAE_time_list.append(MAE_time)\n",
    "    MAE_no_time_list.append(MAE_no_time)\n",
    "    k_list.append(k)\n",
    "plt.figure()\n",
    "plt.xlabel(\"number of neighbourhood\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.plot(k_list,MAE_time_list,c=\"green\",label=\"consider dynamic user interest\")\n",
    "plt.plot(k_list,MAE_no_time_list,c=\"red\",label=\"do not consider dynamic user interest\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "b743e9b8113644f7",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MovieLens100K' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 35\u001B[0m\n\u001B[1;32m     32\u001B[0m     user_timestamp_dict[user_id]\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m*\u001B[39mnum_movie)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m#append rating data set to user rating dict\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m data_set_list\u001B[38;5;241m=\u001B[39m\u001B[43mdata_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m()\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m each_row \u001B[38;5;129;01min\u001B[39;00m data_set_list:\n\u001B[1;32m     37\u001B[0m     user_id\u001B[38;5;241m=\u001B[39meach_row[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'MovieLens100K' object has no attribute 'tolist'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T23:02:06.935109Z",
     "start_time": "2024-09-16T23:01:56.140154Z"
    }
   },
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt",
   "id": "3b59696fa87df16e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T23:02:06.943378Z",
     "start_time": "2024-09-16T23:02:06.942030Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "61c28ac28358aa27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "317989b425479ff1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
